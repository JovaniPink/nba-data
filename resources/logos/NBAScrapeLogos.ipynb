{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Logo Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# https://docs.python.org/3/library/datetime.html\n",
    "import datetime as dt\n",
    "\n",
    "# https://docs.python.org/3/howto/regex.html\n",
    "import re\n",
    "\n",
    "# https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# https://splinter.readthedocs.io/en/latest/#\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Splinter to Download HTML\n",
    "\n",
    "But first you want to check when the last time the splinter code was last ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and last updated on 28 Dec 2020\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from os import scandir\n",
    "\n",
    "\n",
    "def convert_date(timestamp):\n",
    "    d = dt.datetime.utcfromtimestamp(timestamp)\n",
    "    formated_date = d.strftime(\"%d %b %Y\")\n",
    "    return formated_date\n",
    "\n",
    "\n",
    "file = pathlib.Path(\"nbapage.html\")\n",
    "if file.exists():\n",
    "    info = file.stat()\n",
    "    print(f\"File already exists and last updated on {convert_date(info.st_mtime)}\")\n",
    "else:\n",
    "    # Using Splinter to automate the browser actions\n",
    "    # Initiate headless driver for deployment\n",
    "    with Browser(\"chrome\", executable_path=\"chromedriver\", headless=True) as browser:\n",
    "        # Visit URL\n",
    "        url = \"https://cdn.nba.com/\"\n",
    "        browser.visit(url)\n",
    "\n",
    "        # I know the current URL I've passed to visit\n",
    "        # is the site that holds all the logos I am looking for\n",
    "        # so I just save the site and start working with bs4\n",
    "\n",
    "        # Scrape page into soup\n",
    "        html = browser.html\n",
    "\n",
    "        # Save HTML to local machine so we don't continue to requests\n",
    "        with open(\"nbapage.html\", \"w\", encoding=\"utf8\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "# browser = Browser(\"chrome\", executable_path=\"chromedriver\", headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current HTMl file\n",
    "# opened_html = \"\"\n",
    "\n",
    "# Read in local HTML page\n",
    "with open(\"nbapage.html\", \"r\", encoding=\"UTF-8\", errors=\"strict\") as f:\n",
    "    opened_html = f.read()\n",
    "\n",
    "    # Scrape page into soup\n",
    "    soup = bs(opened_html, \"html.parser\")\n",
    "\n",
    "    # Print out the html structure to plan out the scraping logic\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    # I want to find all the image tags and filter down to a list of logo URLs\n",
    "    list_of_img_tags = soup.find_all(\"img\")\n",
    "    # print(list_of_img_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt\\=\\\"[\\w\\s]+Logo\\\"\n",
      "re.compile('[\\\\w\\\\s]+Logo')\n"
     ]
    }
   ],
   "source": [
    "# Create regex pattern this is not used\n",
    "regex = r\"alt\\=\\\"[\\w\\s]+Logo\\\"\"\n",
    "print(regex)\n",
    "# bs4 allowes you to get the alt attribute content so no need to match\n",
    "alt_text_pattern = re.compile(r\"[\\w\\s]+Logo\")\n",
    "print(alt_text_pattern)\n",
    "\n",
    "img_url_list = []\n",
    "\n",
    "for img in list_of_img_tags:\n",
    "    matchObj = alt_text_pattern.fullmatch(img.get(\"alt\"))\n",
    "    if matchObj:\n",
    "        img_url_list.append(\n",
    "            dict([(\"Team Name\", img.get(\"alt\")), (\"URL\", img.get(\"src\"))])\n",
    "        )\n",
    "\n",
    "# print(img_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images with Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sucessfully Downloaded: nba-logo\n",
      "Image sucessfully Downloaded: boston-celtics-logo\n",
      "Image sucessfully Downloaded: brooklyn-nets-logo\n",
      "Image sucessfully Downloaded: new-york-knicks-logo\n",
      "Image sucessfully Downloaded: philadelphia-76ers-logo\n",
      "Image sucessfully Downloaded: toronto-raptors-logo\n",
      "Image sucessfully Downloaded: chicago-bulls-logo\n",
      "Image sucessfully Downloaded: cleveland-cavaliers-logo\n",
      "Image sucessfully Downloaded: detroit-pistons-logo\n",
      "Image sucessfully Downloaded: indiana-pacers-logo\n",
      "Image sucessfully Downloaded: milwaukee-bucks-logo\n",
      "Image sucessfully Downloaded: atlanta-hawks-logo\n",
      "Image sucessfully Downloaded: charlotte-hornets-logo\n",
      "Image sucessfully Downloaded: miami-heat-logo\n",
      "Image sucessfully Downloaded: orlando-magic-logo\n",
      "Image sucessfully Downloaded: washington-wizards-logo\n",
      "Image sucessfully Downloaded: denver-nuggets-logo\n",
      "Image sucessfully Downloaded: minnesota-timberwolves-logo\n",
      "Image sucessfully Downloaded: oklahoma-city-thunder-logo\n",
      "Image sucessfully Downloaded: portland-trail-blazers-logo\n",
      "Image sucessfully Downloaded: utah-jazz-logo\n",
      "Image sucessfully Downloaded: golden-state-warriors-logo\n",
      "Image sucessfully Downloaded: la-clippers-logo\n",
      "Image sucessfully Downloaded: los-angeles-lakers-logo\n",
      "Image sucessfully Downloaded: phoenix-suns-logo\n",
      "Image sucessfully Downloaded: sacramento-kings-logo\n",
      "Image sucessfully Downloaded: dallas-mavericks-logo\n",
      "Image sucessfully Downloaded: houston-rockets-logo\n",
      "Image sucessfully Downloaded: memphis-grizzlies-logo\n",
      "Image sucessfully Downloaded: new-orleans-pelicans-logo\n",
      "Image sucessfully Downloaded: san-antonio-spurs-logo\n",
      "Image sucessfully Downloaded: nba-store-logo\n",
      "Image sucessfully Downloaded: nba-foundation-logo\n",
      "Image sucessfully Downloaded: nba-foundation-logo\n",
      "Image sucessfully Downloaded: nba-logo\n",
      "Image sucessfully Downloaded: warner-media-logo\n"
     ]
    }
   ],
   "source": [
    "## Importing Necessary Modules\n",
    "# https://requests.readthedocs.io/en/master/\n",
    "# https://docs.python.org/3/library/shutil.html#module-shutil\n",
    "import shutil  # to save it locally\n",
    "\n",
    "import requests  # to get image from the web\n",
    "\n",
    "# Looping through the img_url_list and downloading\n",
    "for i in img_url_list:\n",
    "    response = requests.get(i[\"URL\"], stream=True)\n",
    "    if response.status_code == 200:\n",
    "        response.raw.decode_content = True\n",
    "\n",
    "        # prep image file name\n",
    "        processed_file_name = i[\"Team Name\"].lower().replace(\" \", \"-\")\n",
    "\n",
    "        with open(f\"{processed_file_name}.svg\", \"wb\") as f:\n",
    "            shutil.copyfileobj(response.raw, f)\n",
    "\n",
    "        print(f\"Image sucessfully Downloaded: {processed_file_name}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Image Couldn't be retreived\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
